[TOC]

<!-- toc -->
## 业务/数据盘点的目的

* 盘点的目的
    * 摸家底
        * 都有哪些业务？对应有哪些系统？摸清系统建设情况、数据量、数据字典等等信息
    * 为后续接入/建模做准备
        * 通过盘点来决定哪些数据要接入以及接入方式
        * 通过了解业务及数据为后续仓库建模做准备, 比如了解业务后做数仓的主题分类
    * 了解业务部门需求
        * 了解业务方对数据有哪些需求？如果某些业务部门自己都不知道有什么需求, 那就需要通过调研找到数据更好服务业务的创新点

## 业务/数据盘点流程

> 业务调研

* 理清楚业务流程图, 就是用于描述和分析业务流程中的各个步骤和活动, 比如开始做什么, 后续有什么不同的步骤, 会有什么样的最终结果
* 与各个业务部门进行对接, 了解部门数据的对接方式, 数据量, 每日数据增量, 数据库类型等等信息
  
> 系统级分析
  
* 哪些业务系统已经没人用了或者价值很小, 那么这部分的数据就没必要接入, 同时该系统也可以停掉
  
> 表级分析
  
* 针对每个业务系统的表来分析是否有必要接入, 不是所有数据都需要汇聚进入资源池中，需要梳理出有业务价值的表
* 符合以下条件的, 一般可以不用接入
  * 汇总表、临时表、冗余表、备份表（数据涵盖相同业务）
  * 基本配置表、内部人员信息表
  * 老系统使用但已废除信息表，已转移其他数据源信息表
  * 其他数据源存在更加全面的信息表
  * 内部后台系统使用表
  * 记录数量为0
    
> 字段级分析
  
* 这一步工作量最大, 需要弄清每个表的字段含义, 以及字段值的一些特殊情况, 比如是不是敏感字段, 是不是主健唯一健, 字段值的数据字典是怎么样的, 方便后续做一些加密解密的处理

        
## 数据接入方式

> 结构化接入

常用数据库MySQL、Oracle、SQL Server、DB2等，支持扩展, 基本百分之955以上数据都是结构化数据

* 单表接入
    * 全量接入
        * 覆盖模式 (场景：1 数据初始化 2 代码表 3 业务表但无明显增量判定条件 4 变化频率低，数据量较少)
        * 追加模式 (场景：业务表但无明显增量判定条件 需要保留数据切片用以追溯数据变化，最常用的切片表)
    * 增量接入 (场景：1 业务表，可判断数据增量，日志表、流水表)
* 整库接入 (场景：批量初始化)

* sql 条件方式接入 (场景：需要过滤或处理数据)

> API数据接入

API 数据接入能够通过 API方式获取在线数据并自动解析，将解析结果进行写入映射，实现 API 数据的采集

> 半结构化接入

半结构化接入支持包括以下几类方式的接入
* Kafka接入
* MongoDB接入
* ES接入

> 非结构化接入

非结构化数据接入是指把文件、图片、视频等接入到HDFS, OSS 系统,中

> 实时接入

支持利用 CDC 技术，对源表提取数据，并将变化的数据保存到 Kafka 消息队列中。支持通过flinksql、storm、sparksql等实时流数据处理

<!-- tocstop -->